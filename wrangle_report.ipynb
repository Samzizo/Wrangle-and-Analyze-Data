{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction :\n",
    ">Real world data rarely comes clean. Using Python and its libraries, we will collect data from a variety of sources and in a variety of formats, evaluate its quality and accuracy, and then clean it up. This is called a **data wrangling.** <br>\n",
    "  In this file, we will provide a full explanation of the data wrangling process, which goes through three important stages:<br>\n",
    "> **1. Gathering data** <br>\n",
    "> **2. Assessing data** \n",
    "> **3. Cleaning data**\n",
    "\n",
    ">The dataset that we will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user [@dog_rates](https://twitter.com/dog_rates), also known as [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because [\"they're good dogs Brent.\"](https://knowyourmeme.com/memes/theyre-good-dogs-brent) WeRateDogs has over 4 million followers and has received international media coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gathering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In this step, I gathered all three pieces of data as described below in the wrangle_act.ipynb notebook.\n",
    ">  #### 1- The WeRateDogs Twitter archive:\n",
    "I Downloaded this file manually by clicking the following link: [twitter_archive_enhanced.csv.](https://support.twitter.com/articles/20170160) Once it is downloaded, I uploaded it and read the data into a pandas DataFrame.\n",
    "\n",
    "> #### 2- The tweet image predictions\n",
    "This file (image_predictions.tsv) is present in each tweet according to a neural network. It is hosted on Udacity's servers and I downloaded it programmatically using the Requests library and the following URL: [here](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
    "\n",
    "> #### 3- Data from the Twitter API\n",
    "Gather each tweet's retweet count and favorite (\"like\") count at the minimum and any additional data you find interesting. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file.<br>\n",
    ">> **Note:** I used [tweet_json.txt](https://video.udacity-data.com/topher/2018/November/5be5fb7d_tweet-json/tweet-json.txt) provided by udacity since Tweeter refuse my API access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this step, I assess them visually and programmatically for quality and tidiness issues\n",
    ">## Quality Issue\n",
    "\n",
    ">### From df_twt_arch :\n",
    ">    **1** - In columns: ('doggo', 'floofer', 'pupper', 'puppo', 'name') 'None' assigned instead of 'NaN' for empty missing data **{visual assessment}**<br>\n",
    "**2** - columns not needed: ('in_reply_to_status_id', 'in_reply_to_user_id','retweeted_status_id',\n",
    "                        'retweeted_status_user_id','retweeted_status_timestamp')\n",
    "        - columns ('source' ,'text','name) need to rename to be familliar with users **{visual assessment}** <br>\n",
    "**3** - column timestamp dtype should be datetime and split into two columns date and time for better visualisation**{programmatic assessment}** <br>\n",
    "**4** - 'tweet_id' must be a string.**{programmatic assessment}** <br>\n",
    "**5** - 'source' column contains tag html. **{visual assessment}** <br>\n",
    "**6** -  column 'name' has values: 'None', 'a', 'O', 'Devón'. **{programmatic assessment}** <br>\n",
    "<br>\n",
    "**7** -  expanded_urls has missing value and inccorrect urls **{programmatic assessment}** and **{visual assessment}**<br>\n",
    "**8** - Rating dinominator must be equal to 10 there are other values:<br>\n",
    "           ( 0, 15, 70, 7, 11, 150, 170, 20, 50, 90, 80, 40, 130, 110, 16, 120, 2) **{programmatic assessment** <br>\n",
    "    \n",
    "> ### From df_img:\n",
    ">   **9**- The predictions ('P1', 'P2', 'P3') columns are not clear and familiar to the reader\n",
    "and have strange predictions  (spatula, barrow, minibus, etc) **{programmatic assessment}**<br> \n",
    "    **10** - Some \"tweet_ids\" have same \"jpg_url\", after checking using the urls: <br>\n",
    "     (https://twitter.com/dog_rates/status/803692223237865472) <br>\n",
    "     (https://twitter.com/dog_rates/status/691416866452082688) <br>\n",
    "     and changing the ids they were the same tweet **{programmatic assessment}** <br>\n",
    "     - ids img does not exist \"Hmm...this page doesn’t exist. Try searching for something else\": **{visual assessment}** <br>\n",
    "    - 759566828574212096 <br>\n",
    "    - 802247111496568832 <br>\n",
    "    - 851953902622658560 <br>\n",
    "    - 842892208864923648 <br>\n",
    "    - 861769973181624320 <br>\n",
    "    - 873697596434513921 <br>\n",
    "    - 888202515573088257<br><br>  \n",
    "    \n",
    ">### From df_json:\n",
    ">   **11** <br>\n",
    "    - Ivalid urls: <span>(https://… )( https:/…) ( https:/t.c…)</span><br>\n",
    "    - 175 duplicated url <br>\n",
    "**{programmatic assessment}**<br>\n",
    "    **12**- retweet_status has one value 'Original tweet', no need it<br>\n",
    " **13** - Tweets missing retweet count and favorite count **{programmatic assessment}** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Tidiness Issue\n",
    "\n",
    ">   **1**- doggo, floofer, pupper, puppo these 4 variables shoule be combined into one categorical variable 'dogtionary'.\n",
    "    **{visual assessment}** <br>\n",
    "    **2**- rating nominator, rating dinominator should be one column since rating dinominator always be 10\n",
    "     **{visual assessment}** <br>\n",
    "    **3**- Dataframes: twitter_archive, image_predictions, and tweet_json, Should be one df (twitter_master_df) **{visual assessment}** <br>\n",
    " **4**- in twitter_master_df: expanded_urls and url have same values **{visual assessment}** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Cleaning Data\n",
    "\n",
    "> Clean all of the issues I documented while assessing.I Performed this cleaning in the \"Cleaning Data\" section in the wrangle_act.ipynb. \n",
    "![img/steps-cleaning.png](img/steps-cleaning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
